{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _Speech Processing Labs 2020: Signals: Module 1_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 1 Sounds and Signals\n",
    "\n",
    "### Learning Objectives: \n",
    "* Identify a periodic signals from a time vs amplitude (time domain) plot\n",
    "* Identify vocal pulses in a time vs amplitude graph, and how this relates to the concepts of period and frequency.\n",
    "* Identify differences in speech sounds based on a spectrogram\n",
    "\n",
    "### Need to know: \n",
    "* Topic Videos: Time domain, Sound source, Periodic signal, Pitch\n",
    "* [How to use Praat](../phon/phon-0-getPraat.ipynb)\n",
    "    * How to open and view a recording,  pitch and spectrum plots and create spectral slices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1.1 Visualizing speech in the time domain\n",
    "\n",
    "### Exercises\n",
    "\n",
    "* Record the following sentences in praat: \n",
    "    * 'Say writer for me'\n",
    "    * 'Say rider for me' \n",
    "\n",
    "* From the time vs amplitude graph, what differences are there between:\n",
    "    * the 's' and the 'a' in 'say'\n",
    "    * the 's' in say and the 'f' in 'for'\n",
    "   \n",
    "* Looking at recordings of 'writer' and 'rider': are there any differences in your tutorial group in how you pronounce the following? Can you see evidence from this from the speech wave?  \n",
    "    * 't' vs 'd'\n",
    "    * 'r' \n",
    "    * 'i' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Add your notes here. Press Esc-m to change this code cell to a markdown cell (or select Markdown in the menu at the top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1.2 Periodicity and Pitch\n",
    "\n",
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "<strong>Note:</strong> The audio links below are to the sound files on the github server as this gets around some issues playing the sounds from the notebook in the chrome browser.  You can download the sounds using those links.  You can also click on the three dots on the right side of the audio player (if visible!) to download from there.  Otherwise, you should be able to find the audio files in your copy of this repository in signals/audio.\n",
    "    \n",
    "</div>\n",
    "\n",
    "\n",
    "* Listen to some recordings from different instruments: \n",
    "    * [Violin](https://laic.github.io/uoe_speech_processing_course/signals/sounds/violin_A4_05_forte_arco-normal.mp3)\n",
    " \n",
    " <audio controls\n",
    "src=\"sounds/violin_A4_05_forte_arco-normal.mp3\">  \n",
    " Your browser does not support the audio element \n",
    "</audio>\n",
    "\n",
    "    * [Oboe](https://laic.github.io/uoe_speech_processing_course/signals/sounds/oboe_A4_15_forte_normal.mp3)\n",
    "    \n",
    " <audio controls\n",
    "src=\"sounds/oboe_A4_15_forte_normal.mp3\">  \n",
    " Your browser does not support the audio element \n",
    "</audio>\n",
    "\n",
    "    * [Flute](https://laic.github.io/uoe_speech_processing_course/signals/sounds/flute_A4_15_forte_normal.mp3)\n",
    "    \n",
    " <audio controls\n",
    "src=\"sounds/flute_A4_15_forte_normal.mp3\">  \n",
    " Your browser does not support the audio element \n",
    "</audio>\n",
    "\n",
    "    * [Bass drum](https://laic.github.io/uoe_speech_processing_course/signals/sounds/bass-drum__025_forte_bass-drum-mallet.mp3)\n",
    "    \n",
    " <audio controls\n",
    "src=\"sounds/bass-drum__025_forte_bass-drum-mallet.mp3\">  \n",
    " Your browser does not support the audio element \n",
    "</audio>\n",
    "\n",
    "\n",
    "\n",
    "* Load the recordings into Praat and measure some pitch periods manually \n",
    "    * Do all of the instruments recordings have the same fundamental frequency? \n",
    "    \n",
    "    \n",
    "#### Optional: \n",
    "* Look at the violin at different registers: \n",
    "\n",
    "    * [Violin A4](https://laic.github.io/uoe_speech_processing_course/signals/sounds/violin_A4_05_forte_arco-normal.mp3)\n",
    " \n",
    " <audio controls\n",
    "src=\"sounds/violin_A4_05_forte_arco-normal.mp3\">  \n",
    " Your browser does not support the audio element \n",
    "</audio>\n",
    "\n",
    "    * [Violin A3](https://laic.github.io/uoe_speech_processing_course/signals/sounds/violin_A3_15_forte_arco-normal.mp3)\n",
    " \n",
    " <audio controls\n",
    "src=\"sounds/violin_A3_15_forte_arco-normal.mp3\">  \n",
    " Your browser does not support the audio element \n",
    "</audio>\n",
    "\n",
    "* Measure the pitch using praat \n",
    "   * What's the difference in Hz\n",
    "   * What's the difference in semitones? (Here's a [semitone calculator](http://www.homepages.ucl.ac.uk/~sslyjjt/speech/semitone.html))\n",
    "\n",
    "\n",
    "* Can you record your own voice with the same pitch \n",
    "    * Is it exactly the same fundamental frequency? \n",
    "\n",
    "\n",
    "* Turn on the spectrogram view in praat.  What sort of differences are there between instruments? \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1.3 Examine the spectrum of a square wave\n",
    "\n",
    "\n",
    "* Load one of the square waves into praat, select a section from the middle of the waveform about 1 second in length, and generate a spectral slice of this portion: \n",
    "\n",
    "  * [square_100Hz.wav](https://laic.github.io/uoe_speech_processing_course/signals/sounds/square_100Hz.wav)\n",
    "\n",
    " <audio controls\n",
    "src=\"sounds/square_100Hz.wav\">  \n",
    " Your browser does not support the audio element \n",
    "</audio>\n",
    "\n",
    "  * [square_200Hz.wav](https://laic.github.io/uoe_speech_processing_course/signals/sounds/square_200Hz.wav)\n",
    "\n",
    " <audio controls\n",
    "src=\"sounds/square_200Hz.wav\">  \n",
    " Your browser does not support the audio element \n",
    "</audio>\n",
    "\n",
    "  * [square_300Hz.wav](https://laic.github.io/uoe_speech_processing_course/signals/sounds/square_300Hz.wav)\n",
    "\n",
    " <audio controls\n",
    "src=\"sounds/square_300Hz.wav\">  \n",
    " Your browser does not support the audio element \n",
    "</audio>\n",
    "\n",
    "\n",
    "  You should see a spectrum showing the component frequencies for the waveform. Try playing individual peaks or groups of peaks. Compare the pitch and timbre of your selections.\n",
    "\n",
    "    \n",
    "* Try the same thing, playing back just a range of frequencies, but this time use the sine waveforms: \n",
    "\n",
    " * [sine_100Hz.wav](https://laic.github.io/uoe_speech_processing_course/signals/sounds/sine_100Hz.wav)\n",
    "\n",
    " <audio controls\n",
    "src=\"sounds/sine_100Hz.wav\">  \n",
    " Your browser does not support the audio element \n",
    "</audio>\n",
    "\n",
    "  * [sine_200Hz.wav](https://laic.github.io/uoe_speech_processing_course/signals/sounds/sine_200Hz.wav)\n",
    "\n",
    " <audio controls\n",
    "src=\"sounds/sine_200Hz.wav\">  \n",
    " Your browser does not support the audio element \n",
    "</audio>\n",
    "\n",
    "  * [sine_300Hz.wav](https://laic.github.io/uoe_speech_processing_course/signals/sounds/sine_300Hz.wav)\n",
    "\n",
    " <audio controls\n",
    "src=\"sounds/sine_300Hz.wav\">  \n",
    " Your browser does not support the audio element \n",
    "</audio>\n",
    "\n",
    "#### Optional: \n",
    "  * Can you create a sound like a square wave, starting from a sine wave?\n",
    "  * Can you create a sound like a sine wave, starting from a square wave?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1.4 Filter by frequency\n",
    "* Load the file [sweep.wav](https://laic.github.io/uoe_speech_processing_course/signals/sounds/sweep.wav) and examine spectral slices at different points in the file.\n",
    "\n",
    " <audio controls\n",
    "src=\"sounds/sweep.wav\">  \n",
    " Your browser does not support the audio element \n",
    "</audio>\n",
    "  \n",
    "  * How is a spectral slice from the beginning of the file different from one at the end? \n",
    "    \n",
    "    \n",
    "* In the praat objects window select the sound sweep object and click on the filter button and select filter one formant. In the box that opens, set a frequency of 2500Hz and a bandwidth of 300Hz, and click OK. You should now have a new object in the list called Sound sweep_filt. \n",
    "\n",
    "  \n",
    "  * How is the waveform and spectrum of this filtered object different the original sound? \n",
    "    \n",
    "    \n",
    "* Try the above filtering process on a speech waveform, with filter frequencies in the typical range of speech formants, using narrow bandwidths of about 50Hz (You can use the recording you made previously)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1.5 Time vs Frequency Tradeoff\n",
    "* Look at/listen to sentences you recorded again in praat \n",
    "\n",
    "\n",
    "* Identify the part of the recording where a speaker says the \"i\" in writer: this is actually a diphthong /ai/\n",
    "    * What happens to the spectral slice if you select everything between the surrounding consonants? \n",
    "    * What happens if you only select the first half? The second half? \n",
    "    * Compare this to /a/ and /i/ separately. Can you now characterize what a diphthong is? \n",
    "    * What happens if you include the surrounding consonants? \n",
    "\n",
    "\n",
    "* What you see on the spectogram view of praat is based on a default **frame window** size of 5ms. What happens when you change this? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 (Extras) Seeing the environment in a sound\n",
    "\n",
    "\n",
    "* Recording conditions: record close to the microphone, or far away (try it in a reverberant space, such as the bathroom!) – what changes? why?\n",
    "     \n",
    "     \n",
    "* Analyse some of the synthetic speech signals: \n",
    "\n",
    " \n",
    "  * [diphone.wav](https://laic.github.io/uoe_speech_processing_course/signals/sounds/diphone.wav)\n",
    "  \n",
    " <audio controls\n",
    "src=\"sounds/diphone.wav\">  \n",
    " Your browser does not support the audio element \n",
    "</audio>\n",
    "  \n",
    "  \n",
    "   * [dnn_parametric.wav](https://laic.github.io/uoe_speech_processing_course/signals/sounds/dnn_parametric.wav)\n",
    "  \n",
    "  <audio controls\n",
    "src=\"sounds/dnn_parametric.wav\">  \n",
    " Your browser does not support the audio element \n",
    "</audio>\n",
    "\n",
    "   * [hmm_parametric.wav](https://laic.github.io/uoe_speech_processing_course/signals/sounds/hmm_parametric.wav)\t\n",
    " \n",
    "  <audio controls\n",
    "src=\"sounds/hmm_parametric.wav\">  \n",
    " Your browser does not support the audio element \n",
    "</audio>\n",
    "\n",
    "  \n",
    "   * [unit_selection1.wav](https://laic.github.io/uoe_speech_processing_course/signals/sounds/unit_selection1.wav)\n",
    "\n",
    "  <audio controls\n",
    "src=\"sounds/unit_selection1.wav\">  \n",
    " Your browser does not support the audio element \n",
    "</audio>\n",
    "\n",
    "  \n",
    "  * [unit_selection2.wav](https://laic.github.io/uoe_speech_processing_course/signals/sounds/unit_selection2.wav)\n",
    "\n",
    "  <audio controls\n",
    "src=\"sounds/unit_selection2.wav\">  \n",
    " Your browser does not support the audio element \n",
    "</audio>\n",
    "\n",
    "\n",
    "  * What are the differences between them? use different tools (your ears, the waveform, the spectrogram)\n",
    "  * In what ways are they similar or different to natural speech?\n",
    "  * Could you tell they are synthetic just by looking at the spectrogram?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
